# Open-environment Machine Learning 问题综述
## by zzh
## 概要
传统机器学习：假设在封闭环境场景中，学习过程中的重要因素保持不变。

越来越多涉及开放环境的实际任务（开放环境机器学习，Open ML），开始受到关注。在开放环境任务中，数据随着时间积累，类似于数据流，而像传统研究那样在收集所有数据后再训练机器学习模型变得十分困难。
本文简要介绍了该研究领域的一些进展，重点关注新兴类别、递减/增量特征、数据分布变化、学习目标多样化等技术，并讨论了一些理论问题。

## 1.简介
典型的机器学习任务，通过优化特定目标从训练数据集中学习一个预测模型，训练数据集由训练示例组成。一个训练示例包含两个部分：描述对象外观的特征向量（实例）和指示相应真实输出的标签。在分类中，标签表示训练实例所属的类别；在回归中，标签是对应实例的实数响应。本文主要集中讨论分类问题。

formally，考虑学习任务 f:X→Y,从训练数据集 D={(x1,y1),…,(xm,ym)}中学习，其中 $x_i$∈X 是特征空间 X中的特征向量，$y_i$∈Y 是给定标签集 Y 中的真实标签。

值得注意的是，当前机器学习大多基于假设在封闭环境场景下的任务，即学习过程中的重要因素保持不变。例如，所有要预测的类别标签都是已知的，描述训练/测试数据的特征从未改变，所有数据来自相同的分布，并且学习过程针对不变的唯一目标进行优化。图1展示了封闭环境机器学习研究中假设的典型不变因素。

##### 特征不变 (feature invariant)：
用于描述事件/对象的特征向量不会改变，无论是训练阶段还是测试阶段，特征的结构和类型是固定的。

##### 学习目标不变 (learning objective invariant)：
图的中心部分显示了从训练数据中学习一个模型，目的是学习特定的预测目标。这个目标在整个过程中保持不变。无论数据的大小或性质如何，模型的优化方向是固定的。

##### 数据分布不变 (data distribution invariant)：
假设训练数据和测试数据来自相同的分布，模型的泛化能力可以直接应用于新数据。

##### 类别标签不变 (class label invariant)：
在训练和测试数据中，类别标签 (✓ 和 ×) 不变。所有的类别在训练阶段是已知的，测试阶段使用的类别标签与训练时相同，不会发生新的类别。

封闭环境的假设提供了一种简化的抽象，使得复杂任务能够更容易地处理，但如今要求新一代能够处理学习过程中重要因素变化的机器学习技术，称为开放环境机器学习（Open-environment Machine Learning），或简称为开放学习（Open Learning）或 Open ML。

解决方案1：提前模拟可能的变化来人工生成大量训练样本，然后将这些数据输入到一个强大的机器学习模型中，例如深度神经网络。

问题：仅在用户对变化有所了解或至少能估计出变化的内容及其发生方式时适用。实际大数据任务中的数据通常是随着时间积累的，例如实例一个接一个地接收，像数据流一样，这使问题变得更加复杂。

解决方案2：仅用新数据对已训练的深度神经网络进行优化

问题：灾难性遗忘

解决方案3：频繁地基于存储的所有接收到的数据进行重新训练

问题：巨大计算和存储成本

解决方案4：持续学习（Continual Learning）,帮助深度神经网络抵御遗忘

问题：需多次扫描大批量训练数据并进行离线训练，面对大数据流的计算和存储问题仍然存在严重的顾虑。

最近关于开放机器学习的研究取得了相当大的进展。本文将简要介绍该研究方向的一些进展，重点关注新兴类别、递减/增量特征、数据分布变化和多样化学习目标等技术，同时也将讨论一些理论问题

## 2.新兴类别 Emerging New Classes
封闭环境的机器学习研究通常假设任何未见实例$\hat{x}$的类别标签必须是提前已知的给定标签集中的成员，即$\hat{y}$∈Y。

然而，现实中并非总是如此。例如，考虑一个机器学习模型辅助的森林疾病监控系统。显然，很难提前列举出所有可能的类别标签，因为有些森林疾病可能是全新的，比如由以前从未在该地区遇到的入侵害虫引发的疾病。能够处理$\hat{y} \notin$Y是开放环境机器学习（Open ML）的基本要求。

有人认为我们可以人为生成一些虚拟的训练样本用于新类别，就像在对抗深度神经网络中常用的训练技巧一样。这里的难点在于我们很难预见可能会出现什么未知类别（在后文中称为 NewClass），而训练一个可以处理所有可能类别的模型是不可能的，或者成本高得难以承受。

如果所有数据都在手中，那么处理 NewClass 可以被视为一种特殊的半监督学习任务。例如，可以为每个已知类别建立一个半监督的大间隔分隔器，对应于最紧密的轮廓线，然后将落在所有轮廓线之外的未标注实例视为 NewClass 实例。实际上，可以通过将未标注数据中的已知类别分布与未知类别分布分离，来近似估计 NewClass 的分布。然而，当数据是随着时间积累时，这类策略就不再直接适用了。(模型无法提前知道未来数据中可能会出现的新类别，因此无法在初始阶段建立准确的类别分隔。)

考虑如下的新兴类别学习场景：一个机器学习模型通过初始训练数据进行训练，然后被部署来处理数据流一样到来的未见实例。对于已知类别的输入实例，训练后的模型应该能够做出正确预测。对于未知类别的输入实例，模型应能够报告遇到一个 NewClass 实例；用户可以为 NewClass 创建一个新标签。在遇到几个 NewClass 实例后，训练后的模型应能够优化/更新，使得 NewClass 成为一个已知类别，并能够准确预测此类输入实例。理想情况下，整个过程不需要基于存储的所有已接收数据进行重新训练，因为这在实际的大数据任务中可能是极其昂贵的，甚至是不可行的。显然，上述描述的是一个有人工参与的无监督/监督混合任务。

### 新兴类别学习与已有学习方法的区别
零样本学习假设借助外部知识（如类别定义/描述/属性等侧信息）工作，这些信息可以帮助关联已见类别与未见类别，因此它可以被视为一种迁移学习；相比之下，新兴类别学习是一种不假设外部知识的一般机器学习设定。换句话说，零样本学习假设未见类别是已知的，尽管它们没有出现在训练数据中，而学习新兴类别则应对的是未知类别这一重大挑战。因此，新兴类别学习的方法更为通用，且可以转换并应用于零样本学习。

开放集识别/分类扩展了拒绝选项（具有拒绝选项的分类旨在避免可能不正确的不确定预测，假设所有类别都已知。），考虑到在测试阶段可能会出现未知类别，其目标是识别已知类别并拒绝 NewClass。然而，它们并不尝试使训练后的模型能够处理 NewClass。一些广义开放集识别研究试图通过假设侧信息的可用性（如在零样本学习中提到的）来识别未知类别，而学习新兴类别则是一种不假设此类外部知识的通用机器学习设定。

### 新兴类别学习与增量学习的关系
新兴类别学习实际上是一种增量学习，强调对训练后的模型只需进行少量修改即可容纳新信息。增量学习的研究有着悠久的历史，大多数研究关注训练样本的增加，即 E-IL（样本增量学习）。增量学习的另外两种类型是 A-IL（属性增量学习）和 C-IL（类别增量学习）。A-IL 关注特征的增加，与本文第3节讨论的内容相关，尽管以往的研究通常致力于在给定所有数据/特征的前提下选择合适的特征空间。C-IL 关注类别的增加，与新兴类别学习相关，尽管以往的研究很少关注 NewClass（新类别）的识别，通常假设增量类别是已知的。

类别发现（Class Discovery）试图发现稀有类别，作为与类别预测分离的过程。如上所述，学习新兴类别是一个无监督/监督混合任务，而这些研究与其第一阶段（主要是无监督部分）有些相关。

### 新兴类别学习的一般解决方案
#### 第一阶段——NewClass 的识别
通过异常检测实现。这里的挑战在于区分 NewClass 数据与已知类别的异常。通常情况下，这并不总是可行的。幸运的是，在许多实际任务中，可以合理假设 NewClass 实例比已知类别的异常“更异常”。如果在原始特征空间中这种假设不成立，我们可以通过核映射或表示学习识别合适的特征空间。之后，NewClass 实例的识别可以简化为流中的异常检测问题，这可以通过孤立森林(isolation forest)等方法解决。
#### 第二阶段——在不牺牲已知类别的性能下优化训练好的模型以容纳 NewClass
对于深度神经网络，为避免灾难性遗忘，通常需要基于所有数据（或至少是精心选择的子样本）进行重新训练，这会带来巨大的计算和存储成本。理想情况下，只需对 NewClass 相关的局部区域进行微调，而不是进行可能严重影响已知类别的全局更改。一种解决方案是利用树/森林模型的优势，仅增量方式修改包含 NewClass 的树叶节点，这甚至不需要存储已知类别数据。其他替代方法包括可以局部化不同类别影响的技术，例如基于全局和局部概述的方法，以便 NewClass 的变化不会显著影响已知类别。

### 特殊情况处理
#### 有多个新类别
可以利用 NewClass 数据的聚类结构。需要注意的是，NewClass 第一次被检测到的时间点与模型优化完成的时间点之间通常存在较大间隔。为了缩短这一间隔，已经有一些努力致力于基于较少的 NewClass 数据进行模型更新。对于包含新类别的多标签学习更具挑战性，因为在这种情况下，NewClass 实例可能也拥有已知类别标签，甚至可能出现在已知类别的密集区域中，这时关键在于检测特征组合和/或标签组合的显著变化。一个相关的研究方向是检查哪些已知类别与 NewClass 紧密相关，且已有一套关于从 NewClass 映射到已知类别的评估方法被开发出来。

#### 训练数据中出现NewClass实例，但由于特征信息不足而被误认为是已知类别实例
这种情况更加复杂，只有一项非常初步的研究曾对此进行探讨。

## 3.递减/增量特征
封闭环境的机器学习研究通常假设所有可能的实例（包括未见过的实例）都位于相同的特征空间中，即 $\hat{x} \in X$。然而，这并不总是成立。例如，在第2节提到的森林疾病监控中，由于某些传感器的电池耗尽，它们可能无法继续发送信号，导致特征减少；而新的传感器可能被部署，导致特征增加。能够处理 $\hat{x} \in \hat{X} \not ={X}$是开放环境机器学习的另一个基本要求。需要注意的是，与新兴类别相比，只需要对新类别进行特殊处理，而消失的类别可以简单忽略；但对于递减和增量特征，必须同时给予关注，因为特征的递减可能会严重降低模型的性能。

考虑以下场景：一个通过初始训练数据训练出来的机器学习模型，被部署来处理像数据流一样到来的未见数据，其中可能包含递减和/或增量特征。对于输入的测试数据，模型应能够做出正确的预测；对于输入的新增训练数据，模型应能够相应地进行优化。理想情况下，整个过程不应需要基于已接收的所有数据进行重新训练。

通常情况下，构建一个能够从𝑋中受益且适用于$\hat{x} \in \hat{X} \not ={X}$
的机器学习模型并不总是可能的，因为机器学习是通过经验来提高性能的，而在大多数情况下，X中的学习经验对$\hat{X}$中的学习可能帮助甚微，尤其当 $X ∩\hat{X} =∅$ 时。例如，图3(a)展示了一个情景，如果第1阶段数据的特征空间和第2阶段数据的特征空间完全不同，那么在第1阶段训练的模型对第2阶段毫无帮助，必须基于第2阶段的特征集从头开始训练一个新模型。

幸运的是，在许多实际任务中，情况往往是 $X ∩\hat{X} \not =∅$。换句话说，尽管许多特征消失了，第1阶段中的一些特征仍然在第2阶段继续有效。例如，不同的传感器可能具有不同的电池寿命，因此在新传感器被部署后，一些旧传感器仍然在工作。正式地说，在第1阶段，$X = X^{de} ∪ X^{s} $，其中 $X^{de}$和$X^{S}$分别表示递减特征集和幸存特征集;在第2阶段，$X = X^{in} ∪ X^{s} $，其中 $X^{in}$表示增量特征集。

## 4.数据分布的变化
封闭环境的机器学习研究通常假设所有数据，包括训练数据和测试数据，都是来自相同分布的独立样本（即 i.i.d. 样本）。然而，这并不总是成立。仍以第2节中提到的森林疾病监控为例，模型可能是在夏季基于该季节接收到的传感器信号构建的，但希望它能够在所有季节中表现良好。图4展示了忽略数据分布变化可能导致性能严重下降的情况，即 $P_{\text{test}}(y|x)$ 受到影响，而 $P_{\text{train}}(y) \neq P_{\text{test}}(y)$ 和 $P_{\text{train}}(x) \neq P_{\text{test}}(x)$。与之相对，概念漂移（concept drift）关注的是 $P_{\text{train}}(y|x) \neq P_{\text{test}}(y|x)$。在领域自适应（domain adaptation）[37, 4, 40] 或迁移学习 [56] 的研究框架下，已经有许多相关的研究进行探讨。需要注意的是，在流数据（stream）环境中，数据分布的变化可能发生在数据流的任何阶段，而不仅仅是测试阶段。处理各种类型的数据分布变化是开放环境机器学习的一个重要要求。

通常，处理数据分布变化并非总是可能的，当数据分布在每时每刻都任意变化，并且无法知道它可能会如何变化时，学习变得非常困难。幸运的是，在许多实际任务中，可以合理地假设当前观察到的数据与最近观察到的数据有密切的关系；换句话说，当前样本与最近的样本通常来自相似甚至相同的分布，且相隔越远，差异越大。因此，我们可以尝试利用数据流中的一些最近数据来帮助模型应对分布变化。

通常的方法包括基于滑动窗口、遗忘机制或集成机制的策略。基于滑动窗口的方法保留最近的样本，丢弃超出窗口范围的旧样本，窗口大小可以是固定的或自适应的。基于遗忘机制的方法为每个样本分配一个权重，并根据样本的“年龄”降低旧样本的权重。基于集成的方法则是自适应地添加或移除集成中的组件学习器，并动态调整学习器在处理新样本时的权重。

大多数基于滑动窗口或集成的方法都需要对数据进行多次扫描。在实际的大数据任务中，通常希望数据流只需扫描一次，且学习过程中所需的存储空间与数据量无关，因为在数据流结束前无法预先知道数据量的大小。最近，一个基于遗忘机制的简单而有效的方法被提出以应对此问题。该方法不需要关于变化的先验知识，并且每个样本在被扫描一次后即可被丢弃，且误差随着迭代直到收敛而逐渐减小。

数据分布变化可能发生在更复杂的情境中，例如在具有丰富结构的数据上。关于这一问题，已有一些关于多实例学习（multi-instance learning）的研究，其关键在于同时考虑袋级别的变化和实例级别的变化。

## 5. 开放环境机器学习:多样化的学习目标

学习 $f: X \to Y$ 的性能可以通过性能度量 $M_f$ 来衡量，比如准确率、F1值和ROC曲线下面积（AUC）。朝着不同的目标学习可能会导致不同的模型，并且这些模型在不同方面具有不同的优势。在一个度量上最优的模型并不意味着它在其他度量上也最优。封闭环境的机器学习研究通常假设将用于衡量学习性能的度量 $M_f$ 是不变且已知的。然而，这并不总是成立。例如，在传感器部署任务中，最初可能会部署许多传感器以追求高监控精度，但在相对较高的精度已经实现后，其他传感器则被部署以确保系统以尽可能低的能耗继续运行。

针对多样化学习目标的学习研究很少。这里的巨大挑战是如何使已经训练好的机器学习模型能够平滑地从一个目标切换到另一个目标，而无需重新收集数据来训练一个全新的模型。有些研究致力于使训练好的模型适应新的目标，基于这样的观察：许多性能度量是相关的；事实上，可以通过利用非线性辅助分类器来优化多种性能度量，同时保持较高的计算效率。这也与模型重用的策略相关。

除了从一个目标切换到另一个目标，多样化学习目标的学习还可以通过同时追求多个目标来实现，前提是这些目标在事先明确已知。这需要借助于帕累托优化（pareto optimization）。形式上，目标是优化 $\min(M1, M2, \dots, Mn)$，其中 $M_i$ 是多个目标；目标越小越好。通常不存在一个在所有目标上都最优的单一模型；相反，目标是寻找帕累托前沿，该前沿上的解在所有目标上都不劣于其他解。图5提供了一个示例，其中解 X 和 Y 在两个目标上同时不劣于其他解，因此它们位于帕累托前沿上。

进化算法（如遗传算法）在实践中常用于帕累托优化，尽管它们经常被批评为纯粹的启发式方法。值得一提的是，最近一些研究试图为进化学习建立理论基础，即通过利用进化机制进行多目标机器学习，并且已经证明，理论上的进展可以帮助设计更强大的新算法，例如一种首次被证明可以比传统算法获得更好近似保证的进化算法。

除了显式的多个目标，隐式的多个目标也需要在开放环境机器学习中得到关注。例如，在某些情况下，用户可能无法明确表达他们的目标，但可以提供偏好反馈，比如“模型1对我来说比模型2更好”。已经有研究表明，通过利用词袋模型（bag of words）等技术，可以为这种隐式目标获得有效的模型，假设每个隐式目标本质上是一种元素目标的组合。

## 6. 理论问题

开放环境机器学习（Open ML）是一个新的研究方向，因此有许多理论问题需要探索。

如图1所示的四条线索中，当前针对新兴类别的学习技术大多基于启发式方法。值得注意的是，当所有数据都可用时，有一些理论结果，例如，当未标注数据中存在新类别时；然而，这些结果在数据随着时间积累的情况下并不直接适用，即数据流中出现新类别的情况。对于递减/增量特征的学习算法已有一些理论分析，但尚缺乏全面的理论研究。基于进化机制的多目标学习的理论基础正在逐步建立，但整体上关于多样化学习目标的问题仍未得到充分探索。关于数据分布变化的学习，已有相对较多的理论研究。例如，概念漂移已有一系列理论探讨，一些算法也通过错误和损失界限、稳定性分析、泛化和遗憾分析等视角进行了理论分析。还有关于放松 i.i.d. 假设的理论研究。

开放环境机器学习的挑战主要在于我们很难提前知道变化会是什么以及如何发生。这与强化学习处理的典型场景非常不同，在这些场景中，学习者通过与环境交互来探索问题空间。一旦在开放环境中发生了变化，强化学习者以前的探索可能会失效，因为问题空间因变化而改变。尽管已有关于将强化学习者适应于变化环境的研究，但变化不应频繁或持续发生。

从技术上讲，在开放环境机器学习中，初始训练集并不包含反映未知变化的数据，因此必须在变化发生后尽快通过少量样本进行充分的模型更新。从这个角度来看，开放环境机器学习在某种程度上与弱监督学习相关。然而，与封闭环境的研究不同，封闭环境强调大多数样本并假设数据呈正态分布，而在开放环境中，少数样本甚至是从未观察到的样本变得更加重要，同时仍需在大多数样本上取得良好的表现。因此，与正态分布相比，更适合考虑重尾分布（尤其是胖尾分布，其中非常罕见的事件可能导致极大的损失，而不是通常研究的长尾分布），因为其尾部不是指数界限的，如图6所示。显然，我们希望学到的模型 $h(x)$ 满足：
$P(E_i(h) \leq \epsilon_i) \geq 1 - \delta_i$
其中，$E_i(h) = P_{x \in X_i}(h_i(x) \neq y)$，$i \in \{1, 2\}$，$y$ 是 $x$ 的真实输出，$0 < \epsilon_1 \leq \epsilon_2 \leq \epsilon$，$\delta_1, \delta_2 < 1$。直观上，这解释了理想模型在图6中 $X_1$ 区域应该有很高的概率达到小于 $\epsilon_1$ 的误差，并且在 $X_2$ 区域达到令人满意的误差 $\epsilon_2$，尽管其误差可以大于 $\epsilon_1$。严格的阈值 $\epsilon$ 用来确保无论发生何种变化，模型的最差表现都在用户可接受的范围内。这与弱监督场景下的安全学习相关，在达到良好的平均表现后优化最坏情况表现的原则可能会有所帮助。因此，总误差为：
$E = E_1(h) + \gamma E_2(h)$
其中，$\gamma$ 是权衡 $X_1$ 和 $X_2$ 区域的系数，用户可以根据这些区域的相对重要性来设定；根据公式2，$E$ 被 $(1 + \gamma) \epsilon$ 所界定。上述理解为将 $X_2$ 区域视为对 $X_1$ 区域学习的正则化力提供了一种视角。

典型的重尾分布包括帕累托分布、柯西分布等。当假设它们代替常用的正态分布时，会出现新的挑战。例如，中央极限定理不成立，且常见的样本统计量（如样本均值和方差）可能具有误导性（即，它们可能与总体均值和方差差异很大）。这些问题必须在开放环境机器学习中考虑。例如，如果输入和输出空间是重尾分布的，经验风险最小化将失效，因为经验风险不再是风险的良好近似。这对学习算法，甚至是简单的 $L1$ 回归来说，都会造成问题。

考虑到数据随时间积累，性能度量需要特别关注。这里的关键在于无论发生何种变化，学习过程都是作为在线学习进行的。与假设为静态在线学习的封闭环境研究不同，开放环境机器学习更关注非静态在线学习。因此，静态遗憾衡量的是学习者的累积损失与最佳常量点之间的差距，而一般的动态遗憾则更合理，它比较的是学习者的累积损失与任何一系列比较器之间的差距。最近有报道表明，使用各种机制的在线凸优化和赌博凸优化取得了最优结果。通过一种简单而有效的重启机制，针对非静态线性赌博问题的近似极小化解在温和条件下已被报道，这比滑动窗口或遗忘机制更适合资源受限的学习任务。

开放环境机器学习还与噪声数据的学习相关，已有许多理论研究，例如。需要注意的是，与封闭环境研究中可以通过平滑等技术简单抑制噪声不同，开放环境中重要信号可能隐藏在被视为噪声的信号中，且罕见的重大事件可能会因为过于简单的平滑处理而被忽略。
## 7. 结论
本文简要介绍了开放环境机器学习的一些研究进展。它难以对所有相关工作进行全面的回顾，更多的是对作者及其同事在这一方向上的探索的简要总结，重点强调了通用的原则和策略，而非具体的学习算法。本文提到的许多策略和想法可以通过各种学习技术实现，并可能在未来探索出不同的优势。需要注意的是，本文将不同的问题分开讨论，而在实际应用中，它们往往同时发生。对于机器学习模型来说，能够在常规情况下取得出色的表现，并在发生意外或不利的情况下依然保持令人满意的性能，这具有根本的重要性。这对于实现鲁棒人工智能至关重要，并且体现了学习软件（learnware）的理想特性。