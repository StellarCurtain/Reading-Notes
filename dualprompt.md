# DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning
## 0.摘要
持续学习旨在使单个模型能够学习一系列任务而不会发生灾难性遗忘。表现最优的方法通常需要一个回放缓冲区来存储过去的原始样本以进行经验回放，然而，由于隐私和内存限制，这会降低其实际价值。在这项工作中，我们提出了DualPrompt，它通过学习一组非常小的参数，称为提示（prompts），来正确引导一个预训练模型学习依次到达的任务，而无需存储过去的样本。DualPrompt提出了一种新颖的方法，附加互补提示到预训练的主干网络上，然后将目标公式化为学习与任务无关和与任务相关的“指令”。实验证实，DualPrompt在类别增量设置下始终表现出最先进的性能。特别是，DualPrompt在缓冲区较大的情况下，超越了最近的先进持续学习方法。
## 1.介绍
持续学习（Continual Learning，CL）的核心目标是通过单个模型学习一系列任务而不发生灾难性遗忘，即在以前看到的数据上性能显著下降。

许多现有方法旨在在持续学习过程中保留和扩展已获得的知识。基于架构的方法通过分配隔离的参数来编码不同任务中学到的知识。然而，这些方法通常会引入大量额外参数，有时还涉及简化的假设，例如已知测试时的任务身份，这属于任务增量学习的范畴。然而，任务增量的设定通常被认为过于简化，因为在现实世界中测试时任务身份是未知的。我们的工作专注于更加困难的类别增量设定，其中测试时任务身份未知。

另一类方法，基于回放的持续学习（CL）方法，通过在回放缓冲区中保留来自之前任务的数据，直接保存过去的知识。由于其概念简单、对多种设置的普适性以及卓越的减缓灾难性遗忘的能力，基于回放的方法在具有挑战性的类别增量设定中被广泛认为是当前最先进的。然而，这些方法的性能对缓冲区的大小非常敏感，且无法用于存在隐私问题的应用场景或内存预算极其有限的情况。

一种最近的方法，学习提示（Learning to Prompt, L2P）从全新的角度解决了这个问题——它提出利用可学习的提示参数来编码知识，这种方式比缓冲区更为简洁（即提示池），因此不再需要回放缓冲区。提示技术最初是在自然语言处理（NLP）中引入的，用于大型预训练模型的任务适应，通过附加固定或可学习的“指令”，提示旨在指导模型正确重用已学到的表示，而不是从头学习新的表示。L2P成功地将学习新任务的问题公式化为在预训练的冻结模型上训练附加的小提示参数。L2P在无回放的持续学习上迈出了令人振奋的一步，尽管其性能仍低于基于回放的方法。

在L2P中，设计了一个单一的提示池，在任务之间传递知识，而不区分任务之间的通用特征和每个任务独有的特征。从互补学习系统（CLS）理论的角度来看，我们认为这种设计可能是次优的，许多最近的高级CL方法都基于这一直觉。CLS表明，人类通过两个学习系统的协同作用不断学习：海马体专注于学习特定经验的分离模式表示，而新皮层专注于从过去的经验序列中学习更通用且可转移的表示。因此，他们能够独立学习任务特定的知识而不会产生干扰，同时利用任务不变的知识来提高学习未来任务的能力。然而，以前的CLS驱动方法仍然将主干参数分离或扩展为学习这两类知识[12,45,46]。因此，它们仍然依赖于反复构建回放缓冲区来整合分离的知识，以防止灾难性遗忘。

在本文中，我们提出了DualPrompt，这是一种无回放的持续学习方法，能够明确学习两组独立的提示空间，分别是G（通用）提示和E（专家）提示，它们分别编码任务不变和任务特定的指令。DualPrompt直接分离了高层次的提示空间，事实证明，这比传统方法更有效且更节省内存，后者主要关注较低层次的潜在表示空间。我们进一步探讨了在何处以及如何附加这两种提示，对于引导主干模型在减少遗忘的情况下进行学习并实现有效的知识共享至关重要，从而显著提高了持续学习的效果。

此外，我们向社区引入了Split ImageNet-R，这是一个基于ImageNet-R[16]的新CL基准。在Split ImageNet-R中，每个任务的类内多样性很大（参见附录E中的代表性示例），因此一个小的缓冲区不足以代表过去的经验。图1展示了即使是高级方法也需要非凡的回放缓冲区大小才能表现良好。尽管基于回放的方法需要一个大缓冲区（占总训练数据的20%）才能达到有竞争力的平均准确率，但我们的方法DualPrompt在不使用任何回放缓冲区的情况下表现优异。

## 4.DualPrompt
我们提出的方法，DualPrompt，如图2所示。我们首先在第4.1节中介绍互补学习组件G-和E-prompts，并展示它们如何与单个多头自注意力（MSA）层协同工作。然后，我们探讨在第4.2节中如何选择将prompts附加到主干网络上的设计选择。最后，我们在第4.3节中展示了DualPrompt的总体目标。

### 4.1 互补的G-Prompt和E-Prompt

给定一个预训练的ViT模型，具有N个连续的MSA层，表示第i个MSA层的输入嵌入特征为$h^{(i)}，i = 1, 2, ..., N$。

#### G-Prompt：

$g ∈ ℝ^{L_g×D}$，序列长度为$L_g$，嵌入维度为D，是所有任务的共享参数。假设我们希望将G-Prompt附加到第i个MSA层，G-Prompt通过提示函数将$h^{(i)}$转换为：

$h_g^{(i)} = f_{prompt}(g, h^{(i)})，(1)$

其中$f_{prompt}$定义了如何将提示附加到隐藏的嵌入中。

#### E-Prompt：

$E = \{e_t\}_{(t=1)}^T$ 是一组与任务相关的参数，其中$e_t ∈ ℝ^{L_e×D}$，序列长度为$L_e$，嵌入维度为D，T是任务总数。与共享的G-Prompt不同，每个$e_t$都与一个任务特定的键$k_t ∈ ℝ^D$相关联，该键也是一个可学习的参数，旨在捕捉任务的代表性特征。对于来自第t个任务的输入样本，将E-Prompt附加到第j个MSA层，应用提示函数的方式类似：

$h_e^{(j)} = f_{prompt}(e_t, h^{(j)})。(2)$

此外，我们通过匹配损失$L_match$更新对应的$k_t$，以使得$k_t$与来自第t个任务的实例特征比其他键“更接近”。我们对测试样本采用查询函数q，搜索来自任务键的最佳匹配，并选择对应的E-Prompt使用。尽管设计各种匹配和查询策略并引入额外组件是有趣的，但为了不违反持续学习中的简约性原则，我们可以直接使用整个预训练模型作为查询函数：q(x) = f(x)[0]（与[class] token对应的特征向量[11]），以及作为γ的余弦相似性。因此，匹配损失的形式如下：

$L_{match}(x, k_t) = γ(q(x), k_t)，x ∈ D_t。(3)$

对于一个测试样本x，我们简单选择通过$argmin_t γ(q(x), k_t)$的最佳匹配任务键索引。我们在附录I中展示了查询准确性和最终性能之间的关系。我们通过实验发现，这种匹配损失和相应的查询机制对所有基准测试都能很好地工作。

### 4.2 提示附加：在哪里以及如何？

G- 和 E-prompts 在训练时为主干网络编码各自的指令类型，并协同指导模型在推理时进行预测。我们已经在第4.1节中展示了如何将它们附加到单个MSA层上。大多数现有的与提示相关的工作仅简单地将提示放置在第一个MSA层，或每个MSA层上。然而，我们认为，探索在何处以及如何附加这两种提示至关重要。

#### where：解耦提示位置。

直观上，主干网络的不同层具有不同级别的特征抽象。因此，当顺序地学习任务时，某些表示层可能对任务特定知识的响应比其他层更强，反之亦然，任务不变知识亦是如此。这促使我们给予这两种提示更多的灵活性，使其能够以解耦的方式附加到最合适的位置，从而不同的指令能够与相应的表示更有效地交互。

我们引入两种提示的多层扩展：$g = {g^{(l)}}_{l=start_g}^{end_g}$，其中$g^{(l)} ∈ ℝ^{L_g×D}$ 是要附加到第$l$个MSA层的G-Prompt。我们同样定义$e_t = {e_t^{(l)}}_{(l=start_e)}^{(end_e)}$。通过这种方式，我们能够将G-Prompt $g^{(l)}$ 附加到从$start_g-th$到$end_g-th$的MSA层，E-Prompt $e_t^{(l)}$ 附加到从$start_e-th$到$end_e-th$的MSA层。最重要的是，$(start_g, end_g)$ 和 $(start_e, end_e)$ 可能完全不同或不重叠。在我们的实验中，我们通过在验证集上搜索一组$(start_g, end_g, start_e, end_e)$ 发现，它在不同的基准测试中始终表现良好。

#### how：可配置的提示函数。

提示函数$f_{prompt}$控制了我们如何将提示与嵌入特征结合起来。从另一个角度看，$f_{prompt}$ 直接影响了提示中的高层指令如何与低层表示进行交互。因此，一个精心设计的提示函数对于持续学习的整体性能至关重要。这里我们展示并研究了NLP社区的两种主流实现：Prompt Tuning (Pro-T) 和Prefix Tuning (Pre-T)。

具体来说，应用提示函数可以视为修改MSA层的输入。设MSA层的输入为$h ∈ ℝ^{(L×D)}$，我们进一步定义MSA层的输入查询、键和值分别为$h_Q, h_K, h_V$。回想一下，MSA层由[57]提出：

$MSA(h_Q, h_K, h_V) = Concat(h_1, ..., h_m) W^O$

$h_i = Attention(h_Q W^Q_i, h_K W^K_i, h_V W^V_i)$

其中，$W^O, W^Q, W^K, 和 W^V$ 是投影矩阵。m是head的数量。在ViT中，$h_Q = h_K = h_V$。为简化起见，我们定义统一提示参数$p ∈ ℝ^{L_p×D}$ (p可以是单层的G-或E-Prompt)。

#### 提示调优 (Pro-T)

Pro-T 将提示前置于输入tokens之前，这等效于将相同的提示参数p与$h_Q, h_K和h_V$级联，公式为：

$f_{prompt}^{Pro-T}(p, h) = MSA([p; h_Q], [p; h_K], [p; h_V])，(4)$

其中[·; ·]定义了沿序列长度维度的级联操作。输出长度增加，使输出维度为$ℝ^{(L+L_p)×D}$。该操作等效于在第一个MSA层中添加[class]。

#### 前缀调优 (Pre-T)

Pre-T 将p分割为$p_K, p_V$，并分别将其前置于$h_K和h_V$，同时保持$h_Q$不变，公式为：

$f_{prompt}^{Pre-T}(p, h) = MSA(h_Q, [p_K; h_K], [p_V; h_V])$  (5)

与Pro-T相比，输出序列长度保持与输入$h ∈ ℝ^{L×D}$ 相同。

### 4.3 DualPrompt的整体目标

DualPrompt在训练和测试时的全貌分别在算法1和2中描述，见附录A。按照第4.2节中讨论的设计模式，我们将附加提示的架构表示为通过$f_{g,e_t}$。然后，我们通过$f_{g,e_t}$将来自第t个任务的输入x进行转换，并将其发送到由φ参数化的分类头$f_φ$进行预测。最后，我们以端到端的方式训练两种提示、任务键以及新初始化的分类头：

$min_{g,e_t,k_t,φ} L(f_φ(f_g,e_t(x)), y) + λL_{match}(x, k_t), x ∈ D_t$

其中L是交叉熵损失，$L_{match}$是等式3中定义的匹配损失，λ是一个标量平衡因子。

